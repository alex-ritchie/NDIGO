{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.mixture\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KernelCenterer\n",
    "\n",
    "#import code to generate data and do clustNP\n",
    "from sample_distributions import pair_sample_mixture_of_GMs, sample_intersecting_moons\n",
    "from clustNP import clustNP, gauss_kernal_mat, gen_ZG, gen_C, clustNP_obj, proj_simplex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Magic Data and Assign Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) #reproducibility\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('magic04.data', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))\n",
    "n = len(data)\n",
    "X = np.zeros((n,10))\n",
    "Y = np.zeros((n,))\n",
    "\n",
    "for i,row in enumerate(data):\n",
    "    X[i,:] = row[:-1]\n",
    "    y = row[-1] is 'g'\n",
    "    Y[i] = y\n",
    "\n",
    "d = X.shape[1]\n",
    "idxg = np.random.permutation(np.sum(Y==1))\n",
    "idxh = np.random.permutation(np.sum(Y==0))\n",
    "Xg = X[Y==1, :]\n",
    "Xh = X[Y==0, :]\n",
    "Xg = Xg[idxg,:]\n",
    "Xh = Xh[idxh,:]\n",
    "\n",
    "nhold = X.shape[0]//5 # 20% data to test on\n",
    "Xhold = np.zeros((nhold, d))\n",
    "Xhold[0:nhold//2,:] = Xg[-nhold//2:,:]\n",
    "Xhold[nhold//2:,:] = Xh[-nhold//2:,:]\n",
    "Xg = Xg[:Xg.shape[0]-nhold//2,:]\n",
    "Xh = Xh[:Xh.shape[0]-nhold//2,:]\n",
    "\n",
    "# even number of each class, no need to discard\n",
    "# if np.mod(Xg.shape[0], 2) != 0:\n",
    "#     Xg - Xg[:-1,:]\n",
    "# if np.mod(Xh.shape[0], 2) != 0:\n",
    "#     Xh - Xh[:-1,:]\n",
    "\n",
    "\n",
    "# data stacked on top, iid pairs next to each other\n",
    "X = np.vstack((Xg,Xh))\n",
    "n = X.shape[0]\n",
    "mu = np.mean(X, axis=0)\n",
    "sd = np.std(X,axis=0)\n",
    "X = (X-mu)/sd\n",
    "Xhold = (Xhold-mu)/sd\n",
    "\n",
    "component_ids = np.hstack(( np.ones((Xg.shape[0],)) , np.zeros((Xh.shape[0],)) ))\n",
    "cid_hold = np.hstack(( np.ones((nhold//2,)) , np.zeros((nhold//2,)) ))                         \n",
    "pair_ids = [i for i in range(n//2) for j in range(2)]\n",
    "pid_hold = [i for i in range(nhold//2) for j in range(2)]\n",
    "pair_ids = np.array(pair_ids)\n",
    "pid_hold = np.array(pid_hold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2   # true number of mixture components for our KDE\n",
    "d = X.shape[0]   # ambient dimension "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "# do a line search on sigma to find the best eigenvector initialization\n",
    "R = 200\n",
    "best_ISE = 1e10;\n",
    "#sigmas = np.linspace(0.15, 0.3, 50)\n",
    "#sigmas = [0.23]\n",
    "#sigmas = [1]\n",
    "\n",
    "\n",
    "\n",
    "sd = np.min(np.std(X, axis=0))\n",
    "sigma = sd*(R)**(-1/(d+4))\n",
    "Z, G = gen_ZG(X, R, sigma)\n",
    "\n",
    "\n",
    "#Generate initialization for current sigma\n",
    "C = gen_C(X, pair_ids, Z, R, sigma)\n",
    "w, A  = scipy.sparse.linalg.eigs(G, k=M)\n",
    "w = np.real(w)\n",
    "A = np.real(A)\n",
    "for i in range(M):\n",
    "        A[:,i] = proj_simplex(A[:,i])\n",
    "w = w/np.sum(w)\n",
    "A = A / np.sum(A,axis=0)\n",
    "f, _ = clustNP_obj(A, w, G, C, n, 0)\n",
    "#         print(sigma, R, f)\n",
    "#         if f < best_ISE:\n",
    "best_ISE = f\n",
    "best_sigma = sigma\n",
    "best_R = R\n",
    "best_w = w\n",
    "best_Z = Z\n",
    "best_C = C\n",
    "best_G = G\n",
    "best_A = A\n",
    "print(best_sigma, best_R, best_ISE)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = best_sigma\n",
    "R = best_R\n",
    "#w0 = best_w\n",
    "w0 = np.array([0.5, 0.5])\n",
    "Z = best_Z\n",
    "C = best_C\n",
    "G = best_G\n",
    "A0 = best_A\n",
    "#A0 = np.random.rand(R,M)\n",
    "#A0 = A0 / np.sum(A0, axis=0)\n",
    "ss=1\n",
    "\n",
    "print(best_ISE)\n",
    "# #solve\n",
    "f_star, A_star, w_star, Z, n_iter = clustNP(X, pair_ids, A0, w0, Z, G, stepsize=ss, ss_decr=1, \n",
    "                                            epoch_decr = 40, method='psgd', max_iter=5, f_tol=1e-16, \n",
    "                                            grad_tol=1e-8, R=R, sigma=sigma, batch_size=64, backtrack=False,\n",
    "                                            decay=0.2, momentum=0.2, large=True)\n",
    "\n",
    "f_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make predictions\n",
    "phats_train = np.zeros((Xhold.shape[0], M))\n",
    "for i in range(Xhold.shape[0]):\n",
    "    kx = gauss_kernal_mat(Xhold[i, np.newaxis], Z, sigma)\n",
    "    phats_train[i, :] = kx@A_star\n",
    "ltr = np.zeros((Xhold.shape[0], M))\n",
    "for i in set(pid_hold):\n",
    "    ltr[pid_hold==i, :] = np.tile(w_star.T*np.prod(phats_train[pid_hold==i,np.newaxis], axis=0), (2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.sum(cid_hold==1)\n",
    "n0 = np.sum(cid_hold==0)\n",
    "\n",
    "vals = ltr[:,1]/np.sum(ltr, axis=1)\n",
    "thresholds = 1-np.logspace(-5, 0, 201)\n",
    "thresholds[-1] = 0\n",
    "thresholds[0] = 1\n",
    "fprs = []\n",
    "tprs = []\n",
    "for thresh in thresholds:\n",
    "    decisions_train = vals > thresh\n",
    "    cm = sklearn.metrics.confusion_matrix(cid_hold, decisions_train)\n",
    "    fprs.append(cm[0,1]/n0)\n",
    "    tprs.append(cm[1,1]/n1)\n",
    "#     #can't know which cluster label is assigned to each cluster, so if it doesnt work invert labels\n",
    "#     cm = sklearn.metrics.confusion_matrix(component_ids, ~decisions_train)\n",
    "#     fprs.append(cm[0,1]/n0)\n",
    "#     tprs.append(cm[1,1]/n1)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fprs, tprs)\n",
    "ax = plt.gca()\n",
    "ax.axis('square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc = sklearn.metrics.auc(fprs, tprs)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained GMM for paired samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from constr_gmm import constr_gmm\n",
    "M=2\n",
    "constr_gmm = constr_gmm(X,pair_ids,M,20,0)     \n",
    "constr_gmm.run()\n",
    "probs= constr_gmm.predict(Xhold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.sum(cid_hold==1)\n",
    "n0 = np.sum(cid_hold==0)\n",
    "\n",
    "vals = probs[:,0]/np.sum(probs, axis=1)\n",
    "thresholds = 1-np.logspace(-2,0,101)\n",
    "thresholds[0] = 1\n",
    "thresholds[-1] = 0\n",
    "fprs_cgmm = []\n",
    "tprs_cgmm = []\n",
    "for thresh in thresholds:\n",
    "    decisions_train = vals >= thresh\n",
    "    cm = sklearn.metrics.confusion_matrix(cid_hold, ~decisions_train)\n",
    "    fprs_cgmm.append(cm[0,1]/n0)\n",
    "    tprs_cgmm.append(cm[1,1]/n1)\n",
    "#     #can't know which cluster label is assigned to each cluster, so if it doesnt work invert labels\n",
    "#     cm = sklearn.metrics.confusion_matrix(component_ids, ~decisions_train)\n",
    "#     fprs.append(cm[0,1]/n0)\n",
    "#     tprs.append(cm[1,1]/n1)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fprs_cgmm, tprs_cgmm)\n",
    "ax = plt.gca()\n",
    "ax.axis('square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.auc(fprs_cgmm, tprs_cgmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MV-LVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = Xg.shape[0]\n",
    "nh = Xh.shape[0]\n",
    "X1 = np.vstack((Xg[:ng//3,:],Xh[:nh//3,:]))\n",
    "X2 = np.vstack((Xg[ng//3:2*(ng//3),:],Xh[nh//3:2*(nh//3),:]))\n",
    "X3 = np.vstack((Xg[2*(ng//3):3*(ng//3),:],Xh[2*(nh//3):3*(nh//3),:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustering_methods import MVLVM\n",
    "Xa = np.vstack((X1,X2))\n",
    "sd = np.mean(np.std(Xa, axis=0))\n",
    "sigma = sd*(2*n)**(-1/(d+4))\n",
    "A, w = MVLVM(X1,X2,X3,k=2,sigma=sigma,reg=0.01*sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors \n",
    "\n",
    "xmin, xmax = -1.5, 2.5\n",
    "ymin, ymax = -0.9, 1.5\n",
    "xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "#construct kde based on discretization and learned weights\n",
    "#evaluate on grid of points\n",
    "\n",
    "#class 0\n",
    "kde0 = sklearn.neighbors.KernelDensity(bandwidth=sigma);\n",
    "kde0.fit(Xa, y=None, sample_weight=(A[:,0]).clip(1e-16))\n",
    "\n",
    "\n",
    "#class 1\n",
    "kde1 = sklearn.neighbors.KernelDensity(bandwidth=sigma);\n",
    "kde1.fit(Xa, y=None, sample_weight=(A[:,1]).clip(1e-16))\n",
    "\n",
    "vals0 = kde0.score_samples(Xhold)\n",
    "vals1 = kde1.score_samples(Xhold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.sum(cid_hold==1)\n",
    "n0 = np.sum(cid_hold==0)\n",
    "\n",
    "\n",
    "vals = vals0/(vals0+vals1)\n",
    "thresholds = 1-np.logspace(-3,0,101)\n",
    "thresholds[0] = 1\n",
    "thresholds[-1] = 0\n",
    "# thresholds = np.linspace(0.50008, 0.50014, 101)\n",
    "fprs_mvlvm = []\n",
    "tprs_mvlvm = []\n",
    "for thresh in thresholds:\n",
    "    decisions_train = vals >= thresh\n",
    "    cm = sklearn.metrics.confusion_matrix(cid_hold, ~decisions_train)\n",
    "    fprs_mvlvm.append(cm[0,1]/n0)\n",
    "    tprs_mvlvm.append(cm[1,1]/n1)\n",
    "#     #can't know which cluster label is assigned to each cluster, so if it doesnt work invert labels\n",
    "#     cm = sklearn.metrics.confusion_matrix(component_ids, ~decisions_train)\n",
    "#     fprs.append(cm[0,1]/n0)\n",
    "#     tprs.append(cm[1,1]/n1)\n",
    "#     print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fprs_mvlvm, tprs_mvlvm)\n",
    "ax = plt.gca()\n",
    "ax.axis('square')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPMIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NPMIX import NPMIX\n",
    "labels, ofit_gmm, gmm_assn = NPMIX(X, M=M, M_over=2*M)\n",
    "probs = np.zeros((Xhold.shape[0],M))\n",
    "for i in range(M):\n",
    "    probs[:,i] = np.sum(ofit_gmm.predict_proba(Xhold)[:,gmm_assn==i], axis=1)\n",
    "vals1 = np.log(probs[:,1])\n",
    "vals0 = np.log(probs[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.sum(cid_hold==1)\n",
    "n0 = np.sum(cid_hold==0)\n",
    "\n",
    "vals = vals1/(vals0+vals1)\n",
    "thresholds = 1-np.logspace(-12, 0, 201)\n",
    "thresholds[-1] = 0\n",
    "thresholds[0] = 1\n",
    "fprs_npmix = []\n",
    "tprs_npmix = []\n",
    "for thresh in thresholds:\n",
    "    decisions_train = vals >= thresh\n",
    "    cm = sklearn.metrics.confusion_matrix(cid_hold, decisions_train)\n",
    "    fprs_npmix.append(cm[0,1]/n0)\n",
    "    tprs_npmix.append(cm[1,1]/n1)\n",
    "#     #can't know which cluster label is assigned to each cluster, so if it doesnt work invert labels\n",
    "#     cm = sklearn.metrics.confusion_matrix(component_ids, ~decisions_train)\n",
    "#     fprs.append(cm[0,1]/n0)\n",
    "#     tprs.append(cm[1,1]/n1)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fprs_npmix, tprs_npmix)\n",
    "ax = plt.gca()\n",
    "ax.axis('square')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE-plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde0 = scipy.stats.gaussian_kde(X[component_ids==0].T, bw_method='scott')\n",
    "kde1 = scipy.stats.gaussian_kde(X[component_ids==1].T, bw_method='scott')\n",
    "vals0 = kde0(Xhold.T).T\n",
    "vals1 = kde1(Xhold.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = np.sum(cid_hold==1)\n",
    "n0 = np.sum(cid_hold==0)\n",
    "\n",
    "vals = vals1/(vals0+vals1)\n",
    "thresholds = 1-np.logspace(-5, 0, 201)\n",
    "thresholds[-1] = 0\n",
    "fprs_kde = []\n",
    "tprs_kde = []\n",
    "for thresh in thresholds:\n",
    "    decisions_train = vals > thresh\n",
    "    cm = sklearn.metrics.confusion_matrix(cid_hold, decisions_train)\n",
    "    fprs_kde.append(cm[0,1]/n0)\n",
    "    tprs_kde.append(cm[1,1]/n1)\n",
    "#     #can't know which cluster label is assigned to each cluster, so if it doesnt work invert labels\n",
    "#     cm = sklearn.metrics.confusion_matrix(component_ids, ~decisions_train)\n",
    "#     fprs.append(cm[0,1]/n0)\n",
    "#     tprs.append(cm[1,1]/n1)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(fprs_kde, tprs_kde, linestyle=\":\", color=\"c\", linewidth=3)\n",
    "plt.plot(fprs, tprs, linestyle=\"-\", color=\"r\", linewidth=3)\n",
    "plt.plot(fprs_npmix, tprs_npmix, linestyle=\"--\", linewidth=3)\n",
    "plt.plot(fprs_cgmm, tprs_cgmm, linestyle=\":\", color=\"k\", linewidth=3)\n",
    "plt.plot(fprs_mvlvm, tprs_mvlvm, linestyle=\"--\", linewidth=3)\n",
    "plt.plot(np.linspace(0,1,10), np.linspace(0,1,10), linestyle=\"--\", color='k')\n",
    "ax = plt.gca()\n",
    "plt.xlabel(\"FPR\", fontsize=20)\n",
    "plt.ylabel(\"TPR\", fontsize=20)\n",
    "ax.set_aspect('equal', 'box')\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 10}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "labels = ['KDE-plugin', 'NDIGO', 'NPMIX', 'CGMM', 'MVLVM']\n",
    "plt.legend(labels)\n",
    "ax.axis('square')\n",
    "plt.gcf().subplots_adjust(bottom=0.15)\n",
    "# plt.savefig('magicROC.eps', format=\"eps\")\n",
    "# plt.savefig('magicROC.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
